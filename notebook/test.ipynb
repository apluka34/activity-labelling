{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# def detect(\n",
    "#         image: np.ndarray, \n",
    "#         padding: int = 20\n",
    "#         ) -> list:\n",
    "#     \"\"\"\n",
    "#     Perform object detection on the given image using the YOLO model.\n",
    "#     Only returns 'person' objects, with additional padding on the bounding box.\n",
    "\n",
    "#     Args:\n",
    "#         image (np.ndarray): Input image as a numpy array.\n",
    "#         padding (int): Number of pixels to expand the bounding box in all directions.\n",
    "\n",
    "#     Returns:\n",
    "#         list: A list of detected 'person' objects, each as a dictionary\n",
    "#               containing label, confidence, and padded bounding box coordinates.\n",
    "#     \"\"\"\n",
    "#     height, width = image.shape[:2]\n",
    "\n",
    "#     # Convert RGB to BGR (YOLO expects BGR format)\n",
    "#     img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     # Perform inference\n",
    "#     results = model(img, verbose=False)\n",
    "#     result = results[0]\n",
    "\n",
    "#     # Parse detection results\n",
    "#     objects = []\n",
    "#     for xyxy, conf, cls in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
    "#         label = model.names[int(cls)]\n",
    "\n",
    "#         # Filter: Keep only 'person'\n",
    "#         if label != \"person\":\n",
    "#             continue\n",
    "\n",
    "#         # Extract coordinates\n",
    "#         left, top, right, bottom = xyxy.cpu().numpy().astype(int)\n",
    "\n",
    "#         # Apply padding, ensuring we stay within image bounds\n",
    "#         left_padded = max(left - padding, 0)\n",
    "#         top_padded = max(top - padding, 0)\n",
    "#         right_padded = min(right + padding, width - 1)\n",
    "#         bottom_padded = min(bottom + padding, height - 1)\n",
    "\n",
    "#         # Append result\n",
    "#         objects.append({\n",
    "#             \"label\": label,\n",
    "#             \"confidence\": conf.item(),\n",
    "#             \"box\": [left_padded, top_padded, right_padded, bottom_padded]\n",
    "#         })\n",
    "\n",
    "#     return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def draw_detection_boxes(image_path, output_path=None, confidence_threshold=0.2, padding=20, target_size=(640, 640)):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes around detected persons in an image and save the result.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the input image file\n",
    "        output_path (str, optional): Path to save the output image. If None, will add '_boxes' suffix to input path\n",
    "        confidence_threshold (float): Minimum confidence score for detections to be drawn\n",
    "        padding (int): Padding used in the detection function\n",
    "        target_size (tuple): Target size for preprocessing the image for YOLO\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The image with bounding boxes drawn\n",
    "    \"\"\"\n",
    "    # Read the original image for display\n",
    "    original_image = cv2.imread(image_path)\n",
    "    if original_image is None:\n",
    "        print(f\"Error: Could not read image at {image_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Preprocess image for YOLO detection\n",
    "    # preprocessed_image = preprocess_image_for_yolo(image_path, target_size)\n",
    "    # preprocessed_image = resize_image(image_path, target_size)\n",
    "\n",
    "    #save preprocessed image to file\n",
    "    # save_path = \"preprocessed_image.jpg\"\n",
    "    # cv2.imwrite(save_path, preprocessed_image)\n",
    "    \n",
    "    # Run detection on preprocessed image\n",
    "    # detections = detect_version_2(preprocessed_image, padding=padding)\n",
    "\n",
    "    detections = detect_version_2(original_image, padding=padding)\n",
    "    print(len(detections))\n",
    "    # detections_image.save(\"detections_image_2.jpg\")\n",
    "    # print(len(detections))\n",
    "    # print(len(detections_original))\n",
    "    \n",
    "    # # Calculate scale factors to map detections back to original image\n",
    "    # orig_h, orig_w = original_image.shape[:2]\n",
    "    # prep_h, prep_w = preprocessed_image.shape[:2]\n",
    "    \n",
    "    # # Calculate the actual dimensions of the resized image within the preprocessed canvas\n",
    "    # scale = min(prep_w/orig_w, prep_h/orig_h)\n",
    "    # new_w, new_h = int(orig_w * scale), int(orig_h * scale)\n",
    "    \n",
    "    # # Calculate offsets in the preprocessed image\n",
    "    # x_offset = (prep_w - new_w) // 2\n",
    "    # y_offset = (prep_h - new_h) // 2\n",
    "    \n",
    "    # # Draw boxes on both the original and preprocessed images\n",
    "    # preprocessed_with_boxes = preprocessed_image.copy()\n",
    "    \n",
    "    # for det in detections:\n",
    "    #     if det['confidence'] < confidence_threshold:\n",
    "    #         continue\n",
    "            \n",
    "    #     # Get box coordinates from preprocessed image\n",
    "    #     x1, y1, x2, y2 = det['box']\n",
    "        \n",
    "    #     # Draw rectangle on preprocessed image directly\n",
    "    #     cv2.rectangle(preprocessed_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "    #     # Add label with confidence on preprocessed image\n",
    "    #     confidence = det['confidence']\n",
    "    #     label = f\"Person: {confidence:.2f}\"\n",
    "    #     cv2.putText(preprocessed_with_boxes, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "    #     # Adjust for padding and offset in preprocessed image\n",
    "    #     x1 = max(0, x1 - x_offset)\n",
    "    #     y1 = max(0, y1 - y_offset)\n",
    "    #     x2 = min(new_w, x2 - x_offset)\n",
    "    #     y2 = min(new_h, y2 - y_offset)\n",
    "        \n",
    "    #     # Scale back to original image dimensions\n",
    "    #     x1_orig = int(x1 / scale)\n",
    "    #     y1_orig = int(y1 / scale)\n",
    "    #     x2_orig = int(x2 / scale)\n",
    "    #     y2_orig = int(y2 / scale)\n",
    "        \n",
    "    #     # Ensure coordinates are within original image bounds\n",
    "    #     x1_orig = max(0, min(x1_orig, orig_w-1))\n",
    "    #     y1_orig = max(0, min(y1_orig, orig_h-1))\n",
    "    #     x2_orig = max(0, min(x2_orig, orig_w-1))\n",
    "    #     y2_orig = max(0, min(y2_orig, orig_h-1))\n",
    "        \n",
    "    #     # Draw rectangle on original image\n",
    "    #     cv2.rectangle(original_image, (x1_orig, y1_orig), (x2_orig, y2_orig), (0, 255, 0), 2)\n",
    "        \n",
    "    #     # Add label with confidence on original image\n",
    "    #     cv2.putText(original_image, label, (x1_orig, y1_orig-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # # Save the output images\n",
    "    # if output_path is None:\n",
    "    #     filename, ext = os.path.splitext(image_path)\n",
    "    #     output_path = f\"{filename}_boxes{ext}\"\n",
    "    \n",
    "    # # Save original image with boxes\n",
    "    # cv2.imwrite(output_path, original_image)\n",
    "    \n",
    "    # # Save preprocessed image with boxes\n",
    "    # preprocessed_output_path = f\"{os.path.splitext(output_path)[0]}_preprocessed{os.path.splitext(output_path)[1]}\"\n",
    "    # cv2.imwrite(preprocessed_output_path, preprocessed_with_boxes)\n",
    "    \n",
    "    # print(f\"Image with detections saved to {output_path}\")\n",
    "    # print(f\"Preprocessed image with detections saved to {preprocessed_output_path}\")\n",
    "    \n",
    "    return original_image\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
